import os
import json
import time
from difflib import SequenceMatcher
from pathlib import Path
import requests
from bs4 import BeautifulSoup

# --- Google GenAI SDK Imports ---
from google import genai
from google.genai import types
# --------------------------------

# –ó–∞–≥—Ä—É–∑–∫–∞ .env —Ñ–∞–π–ª–∞
def load_env_file():
    # –ò—â–µ–º .env –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (–∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞)
    env_path = Path(__file__).parent.parent / '.env'
    if env_path.exists():
        with open(env_path) as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º os.environ.setdefault –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏, –µ—Å–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞
                    os.environ.setdefault(key.strip(), value.strip())

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_env_file()

# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–ª—é—á–∞ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
API_KEY = os.getenv("GEMINI_API_KEY")
if not API_KEY:
    # NOTE: –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç HTTP-–≤—ã–∑–æ–≤–∞, SDK –ø–æ–ø—ã—Ç–∞–µ—Ç—Å—è –Ω–∞–π—Ç–∏ –∫–ª—é—á,
    # –Ω–æ –ª—É—á—à–µ —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –æ–Ω –µ—Å—Ç—å.
    raise Exception("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é GEMINI_API_KEY")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
DUPLICATE_THRESHOLD = 0.8
RUSSIAN_TEXT_THRESHOLD = 0.8  # –ú–∏–Ω–∏–º—É–º 80% —Ä—É—Å—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
INPUT_FILE = "news_raw.json"
OUTPUT_FILE = "result_news.json"
IMAGES_DIR = "processed_images"

os.makedirs(IMAGES_DIR, exist_ok=True)

def is_duplicate(title, seen_titles):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–º —É–∂–µ –≤–∏–¥–µ–Ω–Ω—ã—Ö."""
    for seen in seen_titles:
        if SequenceMatcher(None, title.lower(), seen.lower()).ratio() > DUPLICATE_THRESHOLD:
            return True
    return False


def is_russian_text(text, threshold=RUSSIAN_TEXT_THRESHOLD):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ —Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –º–∏–Ω–∏–º—É–º threshold% —Ä—É—Å—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤.
    """
    if not text or not text.strip():
        return False
    
    # –î–∏–∞–ø–∞–∑–æ–Ω—ã –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ (–≤–∫–ª—é—á–∞—è —Ä—É—Å—Å–∫–∏–π –∞–ª—Ñ–∞–≤–∏—Ç)
    russian_chars = set('–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è–ê–ë–í–ì–î–ï–Å–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø')
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã (–∏—Å–∫–ª—é—á–∞–µ–º –ø—Ä–æ–±–µ–ª—ã, –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è, —Ü–∏—Ñ—Ä—ã)
    letters = [char for char in text if char.isalpha()]
    
    if not letters:
        return False
    
    russian_count = sum(1 for char in letters if char in russian_chars)
    russian_ratio = russian_count / len(letters)
    
    return russian_ratio >= threshold


def fetch_article_content(url):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç–∞—Ç—å–∏ –ø–æ —Å—Å—ã–ª–∫–µ –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç.
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()

        soup = BeautifulSoup(response.content, 'html.parser')

        # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        for element in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 'iframe']):
            element.decompose()

        # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏ (—Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–∞–π—Ç–æ–≤)
        article_text = ""

        # –ü–æ–ø—ã—Ç–∫–∞ 1: article tag
        article = soup.find('article')
        if article:
            paragraphs = article.find_all('p')
            article_text = ' '.join([p.get_text().strip() for p in paragraphs if p.get_text().strip()])

        # –ü–æ–ø—ã—Ç–∫–∞ 2: –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ –∫–ª–∞—Å—Å–∞–º
        if not article_text:
            content_divs = soup.find_all(['div'], class_=lambda x: x and any(word in str(x).lower() for word in ['article', 'content', 'story', 'post']))
            for div in content_divs:
                paragraphs = div.find_all('p')
                text = ' '.join([p.get_text().strip() for p in paragraphs if p.get_text().strip()])
                if len(text) > len(article_text):
                    article_text = text

        # –ü–æ–ø—ã—Ç–∫–∞ 3: –≤—Å–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
        if not article_text or len(article_text) < 200:
            paragraphs = soup.find_all('p')
            article_text = ' '.join([p.get_text().strip() for p in paragraphs if p.get_text().strip()])

        return article_text[:10000] if article_text else ""  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 10000 —Å–∏–º–≤–æ–ª–æ–≤

    except Exception as e:
        print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç–∞—Ç—å–∏: {e}")
        return ""

def clean_ai_response(text):
    """
    –£–¥–∞–ª—è–µ—Ç –≤–≤–æ–¥–Ω—ã–µ —Ñ—Ä–∞–∑—ã –∏ –º—É—Å–æ—Ä –∏–∑ –æ—Ç–≤–µ—Ç–∞ –ò–ò.
    """
    # –°–ø–∏—Å–æ–∫ —Ñ—Ä–∞–∑, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å
    phrases_to_remove = [
        "–í–æ—Ç –∫—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞:",
        "–ö—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞:",
        "–í–æ—Ç –∫—Ä–∞—Ç–∫–æ–µ –∏–∑–ª–æ–∂–µ–Ω–∏–µ:",
        "–ö—Ä–∞—Ç–∫–æ–µ –∏–∑–ª–æ–∂–µ–Ω–∏–µ:",
        "–í–æ—Ç –ø–µ—Ä–µ–≤–æ–¥:",
        "–ü–µ—Ä–µ–≤–æ–¥:",
        "–í–æ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫:",
        "–ó–∞–≥–æ–ª–æ–≤–æ–∫:",
        "–í–æ—Ç –ø–µ—Ä–µ—Å–∫–∞–∑:",
        "–ü–µ—Ä–µ—Å–∫–∞–∑:",
        "–í–æ—Ç –Ω–æ–≤–æ—Å—Ç—å:",
        "–ù–æ–≤–æ—Å—Ç—å:",
    ]

    result = text.strip()

    # –£–¥–∞–ª—è–µ–º —Ñ—Ä–∞–∑—ã –≤ –Ω–∞—á–∞–ª–µ —Ç–µ–∫—Å—Ç–∞
    for phrase in phrases_to_remove:
        if result.startswith(phrase):
            result = result[len(phrase):].strip()

    # –£–¥–∞–ª—è–µ–º –∫–∞–≤—ã—á–∫–∏ –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
    if (result.startswith('"') and result.endswith('"')) or (result.startswith("'") and result.endswith("'")):
        result = result[1:-1].strip()

    return result

def rewrite_and_translate_with_gemini(text, is_title=False):
    """
    –ü–µ—Ä–µ—Å–∫–∞–∑—ã–≤–∞–µ—Ç –∏ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é Gemini API, –∏—Å–ø–æ–ª—å–∑—É—è –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π SDK.
    """
    try:
        # –ö–ª–∏–µ–Ω—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–π–¥–µ—Ç –∫–ª—é—á –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è GEMINI_API_KEY
        client = genai.Client()
    except Exception as e:
        raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å GenAI –∫–ª–∏–µ–Ω—Ç. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É SDK –∏ –∫–ª—é—á: {e}")

    if is_title:
        prompt = "–¢—ã —Ä–µ–¥–∞–∫—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ Telegram-–∫–∞–Ω–∞–ª–∞ –ø—Ä–æ –∂–∏–∑–Ω—å –≤ –ò—Å–ø–∞–Ω–∏–∏. –ü–µ—Ä–µ–≤–µ–¥–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–æ–≤–æ—Å—Ç–∏ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ –∏ –Ω–µ–º–Ω–æ–≥–æ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –µ–≥–æ, —Å–æ—Ö—Ä–∞–Ω—è—è —Å—É—Ç—å. –ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫—Ä–∞—Ç–∫–∏–º (–¥–æ 10 —Å–ª–æ–≤). –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫, –±–µ–∑ –∫–∞–≤—ã—á–µ–∫, –±–µ–∑ –≤–≤–æ–¥–Ω—ã—Ö —Ñ—Ä–∞–∑, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞. –ó–∞–≥–æ–ª–æ–≤–æ–∫: " + text
    else:
        prompt = "–¢—ã —Ä–µ–¥–∞–∫—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ Telegram-–∫–∞–Ω–∞–ª–∞ –ø—Ä–æ –∂–∏–∑–Ω—å –≤ –ò—Å–ø–∞–Ω–∏–∏. –ü—Ä–æ—á–∏—Ç–∞–π –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏ –∏ —Å–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫—É—é –≤—ã–∂–∏–º–∫—É –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ (5-7 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –º–∞–∫—Å–∏–º—É–º 4000 —Å–∏–º–≤–æ–ª–æ–≤). –°–æ—Ö—Ä–∞–Ω–∏ –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã, —Ü–∏—Ñ—Ä—ã –∏ –¥–µ—Ç–∞–ª–∏. –ù–µ –¥–æ–±–∞–≤–ª—è–π –º–Ω–µ–Ω–∏–π, —Ç–æ–ª—å–∫–æ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ—Å–∫–∞–∑. –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –≤—ã–∂–∏–º–∫–∏, –±–µ–∑ –≤–≤–æ–¥–Ω—ã—Ö —Ñ—Ä–∞–∑ —Ç–∏–ø–∞ '–í–æ—Ç –∫—Ä–∞—Ç–∫–∞—è –≤—ã–∂–∏–º–∫–∞:', –±–µ–∑ –∫–∞–≤—ã—á–µ–∫. –†–∞–∑–±–µ–π –∏—Ç–æ–≥–æ–≤—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ –∞–±–∑–∞—Ü—ã, –µ—Å–ª–∏ —ç—Ç–æ –¥–æ–ø—É—Å—Ç–∏–º–æ. –í –∫–æ–Ω—Ü–µ —á–µ—Ä–µ–∑ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –¥–æ–±–∞–≤—å 3-4 —Ö—ç—à-—Ç—ç–≥–∞ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞. –¢–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏: " + text

    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    # max_output_tokens –æ–≥—Ä–∞–Ω–∏—á–µ–Ω –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞ Telegram –≤ 4096 —Å–∏–º–≤–æ–ª–æ–≤
    # (—Å —É—á–µ—Ç–æ–º –∑–∞–≥–æ–ª–æ–≤–∫–∞, —Å—Å—ã–ª–∫–∏ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
    config = types.GenerateContentConfig(
        temperature=0.7,
        max_output_tokens=2056
    )

    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å gemini-1.5-flash
        response = client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt,
            config=config,
        )

        # SDK –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç —Å –ø–æ–ª–µ–º .text, –∫–æ—Ç–æ—Ä–æ–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç.
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ JSON –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.
        if response.text:
            # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –≤–≤–æ–¥–Ω—ã—Ö —Ñ—Ä–∞–∑
            cleaned_text = clean_ai_response(response.text)
            return cleaned_text

        # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –ø—É—Å—Ç
        return "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç (–æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ –ø—É—Å—Ç)."

    except Exception as e:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ SDK (–Ω–∞–ø—Ä–∏–º–µ—Ä, API_KEY –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω, –ª–∏–º–∏—Ç—ã –∏ —Ç.–¥.)
        print(f"–û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ Gemini API —á–µ—Ä–µ–∑ SDK: {e}")
        raise

def main():
    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ news_raw.json
    input_path = Path(__file__).parent.parent / INPUT_FILE
    output_path = Path(__file__).parent.parent / OUTPUT_FILE

    if not input_path.exists():
        print(f"‚ùå –§–∞–π–ª {INPUT_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ fetch_news.py")
        return

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ news_raw.json
    print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ {INPUT_FILE}...")
    with open(input_path, 'r', encoding='utf-8') as f:
        news_items = json.load(f)

    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(news_items)} –Ω–æ–≤–æ—Å—Ç–µ–π")

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏
    processed_news = []
    seen_titles = []

    for idx, news in enumerate(news_items, 1):
        title = news.get("title", "")
        description = news.get("description", "")

        print(f"\n[{idx}/{len(news_items)}] –û–±—Ä–∞–±–æ—Ç–∫–∞: {title[:50]}...")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç
        if is_duplicate(title, seen_titles):
            print("   ‚ö†Ô∏è  –î—É–±–ª–∏–∫–∞—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
            continue

        seen_titles.append(title)

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Gemini
        try:
            print(f"   ü§ñ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —á–µ—Ä–µ–∑ Gemini...")
            rewritten_title = rewrite_and_translate_with_gemini(title, is_title=True)
            
            # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
            print(f"   ‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ 10 —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –∑–∞–ø—Ä–æ—Å–æ–º...")
            time.sleep(10)

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏ –ø–æ —Å—Å—ã–ª–∫–µ
            link = news.get("link", "")
            print(f"   üîó –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å—Ç–∞—Ç—å–∏...")
            article_content = fetch_article_content(link)

            # –ï—Å–ª–∏ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç–∞—Ç—å—é, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç, –∏–Ω–∞—á–µ —Ç–æ–ª—å–∫–æ title + description
            if article_content:
                text_to_process = f"{title}. {article_content}"
                print(f"   üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(article_content)} —Å–∏–º–≤–æ–ª–æ–≤")
            else:
                text_to_process = f"{title}. {description}"
                print(f"   ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º description")

            print(f"   ü§ñ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Gemini...")
            rewritten_text = rewrite_and_translate_with_gemini(text_to_process)
            
            # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–æ—Å–ª–µ –≤—Ç–æ—Ä–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ (–ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –Ω–æ–≤–æ—Å—Ç—å—é)
            if idx < len(news_items):  # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –ø–æ—Å–ª–µ–¥–Ω—è—è –Ω–æ–≤–æ—Å—Ç—å
                print(f"   ‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ 10 —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –Ω–æ–≤–æ—Å—Ç—å—é...")
                time.sleep(10)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–µ –ø—É—Å—Ç—ã–µ –∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –æ—à–∏–±–∫–∏
            if not rewritten_title or not rewritten_title.strip() or "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç" in rewritten_title:
                print(f"   ‚ö†Ô∏è  –ü—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ò–ò, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–æ–≤–æ—Å—Ç—å")
                continue

            if not rewritten_text or not rewritten_text.strip() or "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç" in rewritten_text:
                print(f"   ‚ö†Ô∏è  –ü—É—Å—Ç–æ–µ –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ò–ò, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–æ–≤–æ—Å—Ç—å")
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –º–∏–Ω–∏–º—É–º 80% —Ä—É—Å—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
            if not is_russian_text(rewritten_title):
                print(f"   ‚ö†Ô∏è  –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å–æ–¥–µ—Ä–∂–∏—Ç –º–µ–Ω–µ–µ 80% —Ä—É—Å—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–æ–≤–æ—Å—Ç—å")
                continue

            if not is_russian_text(rewritten_text):
                print(f"   ‚ö†Ô∏è  –¢–µ–∫—Å—Ç –Ω–æ–≤–æ—Å—Ç–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –º–µ–Ω–µ–µ 80% —Ä—É—Å—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–æ–≤–æ—Å—Ç—å")
                continue

            print(f"   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {rewritten_title[:50]}... / {rewritten_text[:50]}...")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—É—é –Ω–æ–≤–æ—Å—Ç—å
            processed_news.append({
                "title": rewritten_title,
                "link": news.get("link", ""),
                "description": rewritten_text,
                "published": news.get("published", ""),
                "author": news.get("author", ""),
                "categories": news.get("categories", []),
                "image": news.get("image")
            })
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            continue

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ result_news.json
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –≤ {OUTPUT_FILE}...")
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(processed_news, f, ensure_ascii=False, indent=2)

    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(processed_news)} –Ω–æ–≤–æ—Å—Ç–µ–π –≤ {OUTPUT_FILE}")

if __name__ == "__main__":
    main()